{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaination of transformers (For word translation task)\n",
    "## Input encoer, assuming N words\n",
    "- To including the ending symbol, the total length of the input is N+1\n",
    "- Word embedding, set the current input to one and others to be zero, and then feed to a linear network ![Illustration diagram](./pics/transformer/word_embedding.png)\n",
    "- position embedding: use number of word_embedding_space set of the sin or cosine wave to encode the position information ![Illustration diagram](./pics/transformer/position_embedding.png)\n",
    "- Use three linear network to project the output from the position embedding to Query Key and value\n",
    "- Calculate the similarity by dot product between the current Query and all the Keys\n",
    "- Perform softmax operation of the similarity to get the distribution\n",
    "- Elementwise multiply the value vector with the distribution to get the attention output for current word. Self-attention layer could encode the relationships among the input sequence ![Illustration diagram](./pics/transformer/self-attention.png)\n",
    "- Use the residue connection between position embedding output and self-attention output to get the encoder output\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_dim, device, word_latent_space=6, num_head=8) -> None:\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.num_head = num_head\n",
    "        self.word_latent_space = word_latent_space\n",
    "        \n",
    "        self.word_embedding = nn.Sequential(nn.Linear(input_dim, word_latent_space, bias=False),\n",
    "                                            nn.ReLU())\n",
    "        self.query = []\n",
    "        self.key = []\n",
    "        self.value = []\n",
    "        for i in range(num_head):\n",
    "            self.query.append(nn.Linear(word_latent_space, word_latent_space, bias=False))\n",
    "            self.key.append(nn.Linear(word_latent_space, word_latent_space, bias=False))\n",
    "            self.value.append(nn.Linear(word_latent_space, word_latent_space, bias=False))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(x):\n",
    "        # Assuming x is BxN shape\n",
    "        length = x.shape[0]\n",
    "        N = length + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notice for vision transformer (Normally encoder only)\n",
    "## Handling of raw images\n",
    "- Split image into fixed-size patches\n",
    "- Embed each of them via linear tranformation (linear network)\n",
    "- Example: NxCxHxW -> Nx(4xCxH/2xW/2) (Patch) -> Nx(4xD) (Linear projection & position embedding)\n",
    "- Position embedding could be conv2d by change the shape from chw -> embeddding_space*1*1\n",
    "## Handling of image sequences instead of single image\n",
    "- Need to incorporate the sequential information\n",
    "- Spatial-temporal factorization\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
