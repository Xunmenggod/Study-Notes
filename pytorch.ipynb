{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device name: NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if th.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    print(f'device name: {th.cuda.get_device_name()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list test, size: (2, 5)\n",
      "np array test, size: (2, 5)\n",
      "tensor test, tensor: tensor([[ 0.6479, -0.9443, -1.3357]]) size: torch.Size([1, 3]), torch.Size([1, 3])\n",
      "o dimension shape: torch.Size([]), 0\n",
      "['10.png', '8.png', '6.png', '7.png', '5.png', 'side_2.png', '3.png', '4.png', '2.png', 'side_1.png', '1.png', '9.png']\n",
      "['1.png', '10.png', '2.png', '3.png', '4.png', '5.png', '6.png', '7.png', '8.png', '9.png', 'side_1.png', 'side_2.png']\n",
      "data name: 00042\n"
     ]
    }
   ],
   "source": [
    "# torch tensor, python list and numpy array\n",
    "a = [[1,2,3,4,5],[6,7,8,9,10]]\n",
    "b = np.array(a)\n",
    "c  = th.randn(1,3)\n",
    "\n",
    "print(f'list test, size: ({len(a)}, {len(a[0])})')\n",
    "print(f'np array test, size: {b.shape}')\n",
    "print(f'tensor test, tensor: {c} size: {c.shape}, {c.size()}')\n",
    "\n",
    "# o dimensional tensor (scalar)\n",
    "a = th.tensor(1, dtype=th.float32)\n",
    "print (f'o dimension shape: {a.shape}, {len(a.shape)}')\n",
    "\n",
    "import os\n",
    "folders = os.listdir('../grasp_wrs/src/Vacuum-Grasp/vision_processing/scripts/figures')\n",
    "print(folders)\n",
    "folders.sort()\n",
    "print(folders)\n",
    "\n",
    "data_count = 42\n",
    "digit = 5\n",
    "data_name = str(data_count).zfill(digit)\n",
    "print(f'data name: {data_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 2, 4, 3, 4])\n",
      "torch.Size([2, 2, 2, 4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# torch indexing\n",
    "a = th.randn(3,2,2,4,3,4)\n",
    "print(a.shape)\n",
    "print(a[:2, ..., :, :2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([1, 2, 3]), torch.Size([3])\n",
      "a: tensor([1, 2, 3]), torch.Size([3])\n",
      "b: tensor([[ 6.2766e+05,  4.5685e-41,  6.2766e+05,  4.5685e-41],\n",
      "        [ 6.7847e-01,  7.6067e-01,  1.8575e+00, -7.5308e-02],\n",
      "        [ 1.3892e+00, -5.1013e-01,  2.6076e-01, -2.9725e-01]]), torch.Size([3, 4])\n",
      "b: tensor([[6.2766e+05, 4.5685e-41, 3.9551e-35, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 8.4078e-45, 0.0000e+00]]), torch.Size([3, 4])\n",
      "b: tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]]), torch.Size([3, 3])\n",
      "b: tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]]), torch.Size([4, 5])\n",
      "c: tensor([[ 0.2738, -0.0883, -2.0356],\n",
      "        [ 0.1819,  0.8304, -0.5378],\n",
      "        [-0.0831, -0.6756,  0.2318]]), torch.Size([3, 3])\n",
      "d: tensor([[0.8520, 0.7556, 0.8177],\n",
      "        [0.1698, 0.8037, 0.3213],\n",
      "        [0.3510, 0.8716, 0.4748]]), torch.Size([3, 3])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([0, 2, 4, 6, 8])\n",
      "tensor([ 0.,  5., 10.])\n",
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "tensor([1.0000, 0.7743, 0.5995, 0.4642, 0.3594, 0.2783, 0.2154, 0.1668, 0.1292,\n",
      "        0.1000])\n",
      "tensor([ 1.0000,  1.2915,  1.6681,  2.1544,  2.7826,  3.5938,  4.6416,  5.9948,\n",
      "         7.7426, 10.0000])\n"
     ]
    }
   ],
   "source": [
    "# torch creation\n",
    "np_arr = np.array([1,2,3])\n",
    "a = th.from_numpy(np_arr) # share data with original numpy array, th.as_tensor(np_array) also shallow copy\n",
    "print(f'a: {a}, {a.shape}')\n",
    "a = th.tensor(np_arr) # or a = th.tensor([1,2,3]), do not share, do deep copy\n",
    "print(f'a: {a}, {a.shape}')\n",
    "\n",
    "# create by shape\n",
    "b = th.FloatTensor(3,4)\n",
    "print(f'b: {b}, {b.shape}')\n",
    "b = th.empty(3,4)\n",
    "print(f'b: {b}, {b.shape}')\n",
    "b = th.eye(3,3)\n",
    "print(f'b: {b}, {b.shape}')\n",
    "b = th.ones(4,5)\n",
    "print(f'b: {b}, {b.shape}')\n",
    "\n",
    "# random number tensor\n",
    "c = th.randn(3, 3)\n",
    "print(f'c: {c}, {c.shape}')\n",
    "d = th.rand_like(c)\n",
    "print(f'd: {d}, {d.shape}')\n",
    "\n",
    "\n",
    "# some pattern generation\n",
    "print(th.arange(0,10)) # [start, end). end is excluded\n",
    "print(th.arange(0,10,2))\n",
    "print(th.linspace(0,10,steps=3)) # linspace 等差数列\n",
    "print(th.linspace(0,10,steps=11))\n",
    "print(th.logspace(0,-1,steps=10)) # 在10的指数上做等差数列，前两个参数是[start, end]\n",
    "print(th.logspace(0,1,steps=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: torch.Size([1, 2, 1, 2, 2, 1])\n",
      "x.shape: torch.Size([2, 1, 2, 2, 1])\n",
      "x.shape: torch.Size([1, 2, 1, 2, 2, 1])\n",
      "x.shape: torch.Size([2, 2, 2])\n",
      "y.shape: torch.Size([3, 4])\n",
      "y.shape: torch.Size([2, 6])\n",
      "y.shape: torch.Size([2, 6])\n",
      "y.shape: torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# torch shape manipulation\n",
    "## adding/deleting one dimension with size one\n",
    "x = th.randn(1,2,1,2,2,1)\n",
    "print(f'x.shape: {x.shape}')\n",
    "x = x.squeeze(dim=0)\n",
    "print(f'x.shape: {x.shape}')\n",
    "x = x.unsqueeze(dim=0)\n",
    "print(f'x.shape: {x.shape}')\n",
    "x = x.squeeze() # no parameter indicates which dimension to squeeze means squeeze all dimension equals to one\n",
    "print(f'x.shape: {x.shape}')\n",
    "\n",
    "## reshape， view方法和reshape方法有同样的功能呢个但是view有局限性\n",
    "## view方法必须要满足tensor的contigous性质，可以调用.contigous方法去重构数据并开辟新的空间(deep copy)\n",
    "## 如不需要deep copy可以无脑使用reshape方法\n",
    "y = th.randn(3,4)\n",
    "print(f'y.shape: {y.shape}')\n",
    "y = y.reshape(2,6) # y = th.reshape(y, (2,6))\n",
    "print(f'y.shape: {y.shape}')\n",
    "y = th.reshape(y, (2,6))\n",
    "print(f'y.shape: {y.shape}')\n",
    "y = th.randn(2,3,4)\n",
    "y = y.permute(2,1,0)\n",
    "print(f'y.shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "0-dim cat: torch.Size([6, 3])\n",
      "1-dim cat: torch.Size([2, 9])\n"
     ]
    }
   ],
   "source": [
    "# torch stacking and cat\n",
    "x = th.randn(2,3)\n",
    "print(x.shape)\n",
    "concated_x = th.cat((x,x,x),dim=0)\n",
    "print(f'0-dim cat: {concated_x.shape}')\n",
    "concated_x = th.cat((x,x,x),dim=1)\n",
    "print(f'1-dim cat: {concated_x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0.5375],\n",
      "           [0.5653]]],\n",
      "\n",
      "\n",
      "         [[[0.2496],\n",
      "           [0.4502]]]]], grad_fn=<SigmoidBackward0>) torch.Size([1, 2, 1, 2, 1])\n",
      "tensor([[0.5375, 0.5653],\n",
      "        [0.2496, 0.4502]], grad_fn=<SqueezeBackward0>)\n",
      "tensor([[[[[0.5375],\n",
      "           [0.5653]]],\n",
      "\n",
      "\n",
      "         [[[0.2496],\n",
      "           [0.4502]]]]]) torch.Size([1, 2, 1, 2, 1])\n",
      "tensor([[0.5375, 0.5653],\n",
      "        [0.2496, 0.4502]]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Tensor赋值，切片， 变形等等都是进行的shallow copy 如需deep copy请使用clone()的成员函数\n",
    "# tensor clone and detach usage\n",
    "x = th.randn(3,4,5)\n",
    "clone_x = x.clone() # deep copy of x but will be treated as intermediate variable during gradient descend\n",
    "detach_x = x.detach() # shallow copy, will not get involved with gradient calculation\n",
    "clone_detach_x = x.clone().detach() #\n",
    "\n",
    "\n",
    "# test \n",
    "y = th.randn(1,2,1,2,1, requires_grad=True)\n",
    "out = y.sigmoid()\n",
    "print(out,out.shape)\n",
    "out_clone = out.clone().squeeze()\n",
    "print(out_clone)\n",
    "detach_out = out.detach()\n",
    "print(detach_out, detach_out.shape)\n",
    "squezee_out = detach_out.squeeze()\n",
    "print(squezee_out, squezee_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 6, 3, 8])\n",
      "tensor([[1, 2],\n",
      "        [4, 3]])\n"
     ]
    }
   ],
   "source": [
    "# torch logistic selection by api\n",
    "x = th.tensor([1, 2, 3, 4])\n",
    "y = th.tensor([5, 6, 7, 8])\n",
    "condition = th.tensor([True, False, True, False])\n",
    "\n",
    "# torch.where()函数根据条件选择元素\n",
    "result = th.where(condition, x, y) #  true select the first array, false select the second array\n",
    "condition = x < 3\n",
    "compa_result = th.where(condition, x, y) #  result = [1,2,7,8]\n",
    "\n",
    "print(result) #  tensor([1, 6, 3, 8])\n",
    "\n",
    "# gather api for index mapping\n",
    "# 创建示例输入张量\n",
    "input = th.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# 创建索引张量\n",
    "index = th.tensor([[0, 1], [1, 0]])\n",
    "\n",
    "# 在维度 1 上进行索引收集\n",
    "output = th.gather(input, 1, index)  # 在一维数据进行钱两行数据的mapping \n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 37\u001b[0m\n\u001b[1;32m     25\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# data augmentation for images\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# transform = transforms.Compose([\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#     transforms.RandomCrop(size=224),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#     transforms.ToTensor(),\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# ])\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m myDataset \u001b[38;5;241m=\u001b[39m CustomDataset(data, labels, transform\u001b[38;5;241m=\u001b[39m\u001b[43mtransform\u001b[49m)\n\u001b[1;32m     38\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[1;32m     39\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(myDataset, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transform' is not defined"
     ]
    }
   ],
   "source": [
    "# Data set\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        super().__init__(data, labels)\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "\n",
    "# Reading from some directory to get the data and labels \n",
    "data = []\n",
    "labels = []\n",
    "# data augmentation for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(size=224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomErasing(),\n",
    "    transforms.GaussianBlur(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "myDataset = CustomDataset(data, labels, transform=transform)\n",
    "batch_size = 64\n",
    "loader = DataLoader(myDataset, 64, True)\n",
    "\n",
    "# get one batch data\n",
    "x, y = iter(loader)\n",
    "print(f'size of x,y: {(x.shape, y.shape)}') # data shape should be torch tensor (batch_size, (data_size)), (batch_size, (label_size))\n",
    "# normal training procedure\n",
    "num_epoches = 1000\n",
    "for i in range(num_epoches):\n",
    "    # for one epoach training (Used all data inside dataset for one time inside the iteration)\n",
    "    # each data and label are one batch data \n",
    "    for curr_data, true_label in loader:\n",
    "        # train\n",
    "        pass\n",
    "\n",
    "# split dataset to train and test set\n",
    "data_length = myDataset.__len__()\n",
    "train_ratio = 0.8\n",
    "train_length = int(train_ratio * data_length)\n",
    "test_length = data_length - train_length\n",
    "\n",
    "train_dataset, test_dataset = random_split(myDataset, [train_length , test_length])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CustomNet.__init__() missing 2 required positional arguments: 'input_shape' and 'feature_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(lstm_res)\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m---> 34\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mCustomNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# To achieve we training, we still need optimizer to perform gradient descent for updating nn weights\u001b[39;00m\n\u001b[1;32m     36\u001b[0m parser \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mArgumentParser(description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning hyperparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: CustomNet.__init__() missing 2 required positional arguments: 'input_shape' and 'feature_size'"
     ]
    }
   ],
   "source": [
    "# model architecture \n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import tqdm\n",
    "\n",
    "def cal_cnn_size(in_size, kernel_size, stride=1, padding=1):\n",
    "    # if result is not integer, use // operation to do a floor operation to get an int\n",
    "    return (in_size - kernel_size + 2 * padding) // stride + 1\n",
    "\n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, input_shape, feature_size) -> None:\n",
    "        super().__init__()\n",
    "        cnn_output_channel = 32\n",
    "        self.cnn_module = nn.Sequential(\n",
    "            nn.Conv2d(4, cnn_output_channel, kernel_size=7, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(5, stride=2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        cnn_output_size = cnn_output_channel * cal_cnn_size(input_shape[1], 7, 2, 1) * cal_cnn_size(input_shape[2], 7, 2, 1)\n",
    "        self.lstm = nn.LSTM(cnn_output_size, 1024, num_layers=3)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(1024, feature_size),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward pass\n",
    "        cnn_res = self.cnn_module(x)\n",
    "        lstm_res = self.lstm(cnn_res)\n",
    "        out = self.mlp(lstm_res)\n",
    "        return out\n",
    "    \n",
    "net = CustomNet()\n",
    "# To achieve we training, we still need optimizer to perform gradient descent for updating nn weights\n",
    "parser = argparse.ArgumentParser(description=\"learning hyperparameters\")\n",
    "parser.add_argument('--learning_rate', '-lr', type=float, default=0.001, help=\"learning rate\")\n",
    "args = parser.parse_args()\n",
    "optimizer = th.optim.Adam(net.parameters, lr=args.lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for i in range(num_epoches):\n",
    "    for idx, data in tqdm(enumerate(myDataset)):\n",
    "        input = data.unsqueeze(dim=2).float()\n",
    "        true_output = input.clone() #  单步预测\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model_out = net(input)\n",
    "        loss = criterion(model_out, true_output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# obtain the feature map from the pre-trained resenet model\n",
    "import torchvision.models as models\n",
    "\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet_wo_fc = nn.Sequential(*list(resnet.children())[:-1]) # remove the last fc layer\n",
    "# print(resnet)\n",
    "print(resnet_wo_fc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
