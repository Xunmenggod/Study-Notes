{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device name: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "(1, 4, 4)\n",
      "[0 2 4 6 8]\n",
      "ls: [8 6 4 0 2]\n",
      "[[0.         0.         0.        ]\n",
      " [0.81649012 0.50391352 0.89805395]\n",
      " [0.24956833 0.16261661 0.19379982]]\n",
      "idx: (array([1, 2]),)\n",
      "non-zero: [[0.81649012 0.50391352 0.89805395]\n",
      " [0.24956833 0.16261661 0.19379982]]\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if th.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    print(f'device name: {th.cuda.get_device_name()}')\n",
    "\n",
    "a = np.array([1,2,3])\n",
    "b = np.array([])\n",
    "for _ in range(3):\n",
    "    b = np.hstack((b, a))\n",
    "for i in b:\n",
    "    print(i)\n",
    "\n",
    "x = np.ones((4,4))\n",
    "print(x[None, ...].shape)\n",
    "\n",
    "ls = np.arange(0,10,2)\n",
    "print(ls)\n",
    "np.random.shuffle(ls)\n",
    "print(f'ls: {ls}')\n",
    "\n",
    "a = np.random.rand(3,3)\n",
    "a[0] = 0 \n",
    "print(a)\n",
    "idx = np.where(a[:,2]>0)\n",
    "print(f'idx: {idx}')\n",
    "a_non_zero = a[idx]\n",
    "print(f'non-zero: {a_non_zero}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('./', ['.vscode', 'C++Project', '.git', 'optimization', 'Fruit'], ['open3d.ipynb', 'isaacgym.ipynb', '.gitignore', 'scripts.pdf', 'control.md', 'scripts.md', 'programming.md', 'pytorch.ipynb', 'linux.md', 'markdown.md', 'ros.md', 'lstm_example.ipynb'])\n",
      "('./.vscode', [], ['settings.json', 'c_cpp_properties.json'])\n",
      "('./C++Project', ['include', 'build', 'src'], ['CMakeLists.txt'])\n",
      "('./C++Project/include', [], ['hello.h'])\n",
      "('./C++Project/build', ['CMakeFiles'], ['cmake_install.cmake', 'CMakeCache.txt', 'Makefile', 'hello'])\n",
      "('./C++Project/build/CMakeFiles', ['CMakeTmp', 'hello.dir', '3.22.1'], ['Makefile2', 'cmake.check_cache', 'CMakeOutput.log', 'Makefile.cmake', 'CMakeDirectoryInformation.cmake', 'progress.marks', 'TargetDirectories.txt'])\n",
      "('./C++Project/build/CMakeFiles/CMakeTmp', [], [])\n",
      "('./C++Project/build/CMakeFiles/hello.dir', ['src'], ['compiler_depend.make', 'build.make', 'flags.make', 'DependInfo.cmake', 'compiler_depend.ts', 'depend.make', 'progress.make', 'link.txt', 'cmake_clean.cmake', 'compiler_depend.internal'])\n",
      "('./C++Project/build/CMakeFiles/hello.dir/src', [], ['hello.cpp.o', 'hello.cpp.o.d'])\n",
      "('./C++Project/build/CMakeFiles/3.22.1', ['CompilerIdC', 'CompilerIdCXX'], ['CMakeDetermineCompilerABI_CXX.bin', 'CMakeSystem.cmake', 'CMakeCXXCompiler.cmake', 'CMakeCCompiler.cmake', 'CMakeDetermineCompilerABI_C.bin'])\n",
      "('./C++Project/build/CMakeFiles/3.22.1/CompilerIdC', ['tmp'], ['a.out', 'CMakeCCompilerId.c'])\n",
      "('./C++Project/build/CMakeFiles/3.22.1/CompilerIdC/tmp', [], [])\n",
      "('./C++Project/build/CMakeFiles/3.22.1/CompilerIdCXX', ['tmp'], ['CMakeCXXCompilerId.cpp', 'a.out'])\n",
      "('./C++Project/build/CMakeFiles/3.22.1/CompilerIdCXX/tmp', [], [])\n",
      "('./C++Project/src', [], ['hello.cpp'])\n",
      "('./.git', ['hooks', 'objects', 'info', 'branches', 'logs', 'refs'], ['FETCH_HEAD', 'description', 'index', 'COMMIT_EDITMSG', 'config', 'ORIG_HEAD', 'HEAD', 'packed-refs'])\n",
      "('./.git/hooks', [], ['prepare-commit-msg.sample', 'update.sample', 'commit-msg.sample', 'pre-applypatch.sample', 'pre-merge-commit.sample', 'pre-commit.sample', 'pre-receive.sample', 'applypatch-msg.sample', 'pre-rebase.sample', 'post-update.sample', 'fsmonitor-watchman.sample', 'pre-push.sample'])\n",
      "('./.git/objects', ['b1', '09', '33', '0a', '1d', 'pack', '9b', '27', '06', '31', '83', '6b', '45', '9c', 'ae', '7a', 'c0', 'd5', '4f', '0b', 'info', 'e6', 'ad', '7d', 'f6', '6e', 'cc', '14', '40', '64', '49', '02', '94'], [])\n",
      "('./.git/objects/b1', [], ['5dc8d90d9f5d56a54dbd70e8001fe2624ce62d'])\n",
      "('./.git/objects/09', [], ['bcd96859c704cac47983b3e46ee6c4b5894a88'])\n",
      "('./.git/objects/33', [], ['ad6fcae967d1d31e36e4c7f1ecc5db409b1b95'])\n",
      "('./.git/objects/0a', [], ['0b5a899e769d0bb8bf216001d2638adb0c6929'])\n",
      "('./.git/objects/1d', [], ['7781868e443813eb1a30b07ecb5979e4f28713'])\n",
      "('./.git/objects/pack', [], ['pack-05b7d6997ac204689ffa84fce0e5f1db5af2d9ff.idx', 'pack-05b7d6997ac204689ffa84fce0e5f1db5af2d9ff.pack'])\n",
      "('./.git/objects/9b', [], ['f76993b4e932b6a36ea5add834a143899d1fd0'])\n",
      "('./.git/objects/27', [], ['b5cf7e4d9f32c12e4ce3c9e55341663977c446'])\n",
      "('./.git/objects/06', [], ['532f83b813b4943395b486ebc1324529c9ed83'])\n",
      "('./.git/objects/31', [], ['0401b16880951dfa2c86f2659ecb9c037a873e'])\n",
      "('./.git/objects/83', [], ['6ae9d0b71c20978ad56fe895d2c732acdf0b0f'])\n",
      "('./.git/objects/6b', [], ['53a1e66fd5945c9e3978d15abcc7d0dcd52561'])\n",
      "('./.git/objects/45', [], ['224c41d9d7e8f2c1fa8c000ab2d511712b502c'])\n",
      "('./.git/objects/9c', [], ['b93d671a39c43d663624fba1147aa20ad60b8b'])\n",
      "('./.git/objects/ae', [], ['94a097e97adf6798f1a8eb0ac59106b4a49306'])\n",
      "('./.git/objects/7a', [], ['f965db2b5fcb592ecf6157709cff3c7f312c51'])\n",
      "('./.git/objects/c0', [], ['732c2ceaac5e44d4995cdb2ba50e0c6b9ff824'])\n",
      "('./.git/objects/d5', [], ['d7942bf46a3042ac3d78dc46e0dd26b0b84435'])\n",
      "('./.git/objects/4f', [], ['ad8015d0a1b6ca90fafa68e5656f0f989608cd'])\n",
      "('./.git/objects/0b', [], ['40d07a487fc9e3ce74b42275874fabe33952ad'])\n",
      "('./.git/objects/info', [], [])\n",
      "('./.git/objects/e6', [], ['d567430508356ff1aaf4333a838ede0fa3ba6f'])\n",
      "('./.git/objects/ad', [], ['46c8ca2cd7bd3070e9f57952f7483c1fae61ee'])\n",
      "('./.git/objects/7d', [], ['14c794010fe1580584c3cadf47743d86dc467e'])\n",
      "('./.git/objects/f6', [], ['643e54df442a2524974e6ee68afa6992c6868f'])\n",
      "('./.git/objects/6e', [], ['e3d4c7ce79d0522d6d5b9847a4866877cdf7de'])\n",
      "('./.git/objects/cc', [], ['d687b7788bd13dd9aba1c99763450e3d36a1ed'])\n",
      "('./.git/objects/14', [], ['1313f0789a83929f04cbb99ab46eae8b91f945', '7c900cfc67bb1f38d98bd658b2c46276082be6'])\n",
      "('./.git/objects/40', [], ['0f031b7c4520e3ecbfc367247eabd87c1a5d9a'])\n",
      "('./.git/objects/64', [], ['b3c3b25d88f614e23294b225933ce0524dc710'])\n",
      "('./.git/objects/49', [], ['bb9700e1edfc5a23f1e46da9c76ace00bd9a14'])\n",
      "('./.git/objects/02', [], ['e2a7ff4d82301614e4c2c7bfd20319d706cb2b'])\n",
      "('./.git/objects/94', [], ['af66a5bfc29daf2bf99097bb1dca236a0aea30', 'b524bf8fc8acbbed57f0bbb71fbcaa7c2ed85b'])\n",
      "('./.git/info', [], ['exclude'])\n",
      "('./.git/branches', [], [])\n",
      "('./.git/logs', ['refs'], ['HEAD'])\n",
      "('./.git/logs/refs', ['remotes', 'heads'], [])\n",
      "('./.git/logs/refs/remotes', ['origin'], [])\n",
      "('./.git/logs/refs/remotes/origin', [], ['main', 'HEAD'])\n",
      "('./.git/logs/refs/heads', [], ['main'])\n",
      "('./.git/refs', ['tags', 'remotes', 'heads'], [])\n",
      "('./.git/refs/tags', [], [])\n",
      "('./.git/refs/remotes', ['origin'], [])\n",
      "('./.git/refs/remotes/origin', [], ['main', 'HEAD'])\n",
      "('./.git/refs/heads', [], ['main'])\n",
      "('./optimization', ['build'], ['test.cpp', 'CMakeLists.txt'])\n",
      "('./optimization/build', ['CMakeFiles'], ['cmake_install.cmake', 'CMakeCache.txt', 'Makefile', 'test'])\n",
      "('./optimization/build/CMakeFiles', ['CMakeTmp', 'test.dir', '3.22.1'], ['Makefile2', 'cmake.check_cache', 'CMakeOutput.log', 'Makefile.cmake', 'CMakeDirectoryInformation.cmake', 'progress.marks', 'TargetDirectories.txt'])\n",
      "('./optimization/build/CMakeFiles/CMakeTmp', [], [])\n",
      "('./optimization/build/CMakeFiles/test.dir', [], ['compiler_depend.make', 'build.make', 'flags.make', 'DependInfo.cmake', 'compiler_depend.ts', 'test.cpp.o', 'depend.make', 'test.cpp.o.d', 'progress.make', 'link.txt', 'cmake_clean.cmake'])\n",
      "('./optimization/build/CMakeFiles/3.22.1', ['CompilerIdC', 'CompilerIdCXX'], ['CMakeDetermineCompilerABI_CXX.bin', 'CMakeSystem.cmake', 'CMakeCXXCompiler.cmake', 'CMakeCCompiler.cmake', 'CMakeDetermineCompilerABI_C.bin'])\n",
      "('./optimization/build/CMakeFiles/3.22.1/CompilerIdC', ['tmp'], ['a.out', 'CMakeCCompilerId.c'])\n",
      "('./optimization/build/CMakeFiles/3.22.1/CompilerIdC/tmp', [], [])\n",
      "('./optimization/build/CMakeFiles/3.22.1/CompilerIdCXX', ['tmp'], ['CMakeCXXCompilerId.cpp', 'a.out'])\n",
      "('./optimization/build/CMakeFiles/3.22.1/CompilerIdCXX/tmp', [], [])\n",
      "('./Fruit', [], ['banana.ply', 'plum.ply', 'dates.ply', 'bananab.ply', 'final.ply', 'plumb.ply', 'R_4_4_30_90.pkl'])\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "path = './'\n",
    "for x in os.walk(path):\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list test, size: (2, 5)\n",
      "np array test, size: (2, 5)\n",
      "tensor test, tensor: tensor([[ 0.6479, -0.9443, -1.3357]]) size: torch.Size([1, 3]), torch.Size([1, 3])\n",
      "o dimension shape: torch.Size([]), 0\n",
      "['10.png', '8.png', '6.png', '7.png', '5.png', 'side_2.png', '3.png', '4.png', '2.png', 'side_1.png', '1.png', '9.png']\n",
      "['1.png', '10.png', '2.png', '3.png', '4.png', '5.png', '6.png', '7.png', '8.png', '9.png', 'side_1.png', 'side_2.png']\n",
      "data name: 00042\n"
     ]
    }
   ],
   "source": [
    "# torch tensor, python list and numpy array\n",
    "a = [[1,2,3,4,5],[6,7,8,9,10]]\n",
    "b = np.array(a)\n",
    "c  = th.randn(1,3)\n",
    "\n",
    "print(f'list test, size: ({len(a)}, {len(a[0])})')\n",
    "print(f'np array test, size: {b.shape}')\n",
    "print(f'tensor test, tensor: {c} size: {c.shape}, {c.size()}')\n",
    "\n",
    "# o dimensional tensor (scalar)\n",
    "a = th.tensor(1, dtype=th.float32)\n",
    "print (f'o dimension shape: {a.shape}, {len(a.shape)}')\n",
    "\n",
    "import os\n",
    "folders = os.listdir('../grasp_wrs/src/Vacuum-Grasp/vision_processing/scripts/figures')\n",
    "print(folders)\n",
    "folders.sort()\n",
    "print(folders)\n",
    "\n",
    "data_count = 42\n",
    "digit = 5\n",
    "data_name = str(data_count).zfill(digit)\n",
    "print(f'data name: {data_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 2, 4, 3, 4])\n",
      "torch.Size([2, 2, 2, 4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# torch indexing\n",
    "a = th.randn(3,2,2,4,3,4)\n",
    "print(a.shape)\n",
    "print(a[:2, ..., :, :2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([1, 2, 3]), torch.Size([3])\n",
      "a: tensor([1, 2, 3]), torch.Size([3])\n",
      "b: tensor([[ 6.2766e+05,  4.5685e-41,  6.2766e+05,  4.5685e-41],\n",
      "        [ 6.7847e-01,  7.6067e-01,  1.8575e+00, -7.5308e-02],\n",
      "        [ 1.3892e+00, -5.1013e-01,  2.6076e-01, -2.9725e-01]]), torch.Size([3, 4])\n",
      "b: tensor([[6.2766e+05, 4.5685e-41, 3.9551e-35, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 8.4078e-45, 0.0000e+00]]), torch.Size([3, 4])\n",
      "b: tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]]), torch.Size([3, 3])\n",
      "b: tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]]), torch.Size([4, 5])\n",
      "c: tensor([[ 0.2738, -0.0883, -2.0356],\n",
      "        [ 0.1819,  0.8304, -0.5378],\n",
      "        [-0.0831, -0.6756,  0.2318]]), torch.Size([3, 3])\n",
      "d: tensor([[0.8520, 0.7556, 0.8177],\n",
      "        [0.1698, 0.8037, 0.3213],\n",
      "        [0.3510, 0.8716, 0.4748]]), torch.Size([3, 3])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([0, 2, 4, 6, 8])\n",
      "tensor([ 0.,  5., 10.])\n",
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "tensor([1.0000, 0.7743, 0.5995, 0.4642, 0.3594, 0.2783, 0.2154, 0.1668, 0.1292,\n",
      "        0.1000])\n",
      "tensor([ 1.0000,  1.2915,  1.6681,  2.1544,  2.7826,  3.5938,  4.6416,  5.9948,\n",
      "         7.7426, 10.0000])\n"
     ]
    }
   ],
   "source": [
    "# torch creation\n",
    "np_arr = np.array([1,2,3])\n",
    "a = th.from_numpy(np_arr) # share data with original numpy array, th.as_tensor(np_array) also shallow copy\n",
    "print(f'a: {a}, {a.shape}')\n",
    "a = th.tensor(np_arr) # or a = th.tensor([1,2,3]), do not share, do deep copy\n",
    "print(f'a: {a}, {a.shape}')\n",
    "\n",
    "# create by shape\n",
    "b = th.FloatTensor(3,4)\n",
    "print(f'b: {b}, {b.shape}')\n",
    "b = th.empty(3,4)\n",
    "print(f'b: {b}, {b.shape}')\n",
    "b = th.eye(3,3)\n",
    "print(f'b: {b}, {b.shape}')\n",
    "b = th.ones(4,5)\n",
    "print(f'b: {b}, {b.shape}')\n",
    "\n",
    "# random number tensor\n",
    "c = th.randn(3, 3)\n",
    "print(f'c: {c}, {c.shape}')\n",
    "d = th.rand_like(c)\n",
    "print(f'd: {d}, {d.shape}')\n",
    "\n",
    "\n",
    "# some pattern generation\n",
    "print(th.arange(0,10)) # [start, end). end is excluded\n",
    "print(th.arange(0,10,2))\n",
    "print(th.linspace(0,10,steps=3)) # linspace 等差数列\n",
    "print(th.linspace(0,10,steps=11))\n",
    "print(th.logspace(0,-1,steps=10)) # 在10的指数上做等差数列，前两个参数是[start, end]\n",
    "print(th.logspace(0,1,steps=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: torch.Size([1, 2, 1, 2, 2, 1])\n",
      "x.shape: torch.Size([2, 1, 2, 2, 1])\n",
      "x.shape: torch.Size([1, 2, 1, 2, 2, 1])\n",
      "x.shape: torch.Size([2, 2, 2])\n",
      "y.shape: torch.Size([3, 4])\n",
      "y.shape: torch.Size([2, 6])\n",
      "y.shape: torch.Size([2, 6])\n",
      "y.shape: torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# torch shape manipulation\n",
    "## adding/deleting one dimension with size one\n",
    "x = th.randn(1,2,1,2,2,1)\n",
    "print(f'x.shape: {x.shape}')\n",
    "x = x.squeeze(dim=0)\n",
    "print(f'x.shape: {x.shape}')\n",
    "x = x.unsqueeze(dim=0)\n",
    "print(f'x.shape: {x.shape}')\n",
    "x = x.squeeze() # no parameter indicates which dimension to squeeze means squeeze all dimension equals to one\n",
    "print(f'x.shape: {x.shape}')\n",
    "\n",
    "## reshape， view方法和reshape方法有同样的功能呢个但是view有局限性\n",
    "## view方法必须要满足tensor的contigous性质，可以调用.contigous方法去重构数据并开辟新的空间(deep copy)\n",
    "## 如不需要deep copy可以无脑使用reshape方法\n",
    "y = th.randn(3,4)\n",
    "print(f'y.shape: {y.shape}')\n",
    "y = y.reshape(2,6) # y = th.reshape(y, (2,6))\n",
    "print(f'y.shape: {y.shape}')\n",
    "y = th.reshape(y, (2,6))\n",
    "print(f'y.shape: {y.shape}')\n",
    "y = th.randn(2,3,4)\n",
    "y = y.permute(2,1,0)\n",
    "print(f'y.shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "0-dim cat: torch.Size([6, 3])\n",
      "1-dim cat: torch.Size([2, 9])\n"
     ]
    }
   ],
   "source": [
    "# torch stacking and cat\n",
    "x = th.randn(2,3)\n",
    "print(x.shape)\n",
    "concated_x = th.cat((x,x,x),dim=0)\n",
    "print(f'0-dim cat: {concated_x.shape}')\n",
    "concated_x = th.cat((x,x,x),dim=1)\n",
    "print(f'1-dim cat: {concated_x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0.5375],\n",
      "           [0.5653]]],\n",
      "\n",
      "\n",
      "         [[[0.2496],\n",
      "           [0.4502]]]]], grad_fn=<SigmoidBackward0>) torch.Size([1, 2, 1, 2, 1])\n",
      "tensor([[0.5375, 0.5653],\n",
      "        [0.2496, 0.4502]], grad_fn=<SqueezeBackward0>)\n",
      "tensor([[[[[0.5375],\n",
      "           [0.5653]]],\n",
      "\n",
      "\n",
      "         [[[0.2496],\n",
      "           [0.4502]]]]]) torch.Size([1, 2, 1, 2, 1])\n",
      "tensor([[0.5375, 0.5653],\n",
      "        [0.2496, 0.4502]]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Tensor赋值，切片， 变形等等都是进行的shallow copy 如需deep copy请使用clone()的成员函数\n",
    "# tensor clone and detach usage\n",
    "x = th.randn(3,4,5)\n",
    "clone_x = x.clone() # deep copy of x but will be treated as intermediate variable during gradient descend\n",
    "detach_x = x.detach() # shallow copy, will not get involved with gradient calculation\n",
    "clone_detach_x = x.clone().detach() #\n",
    "\n",
    "\n",
    "# test \n",
    "y = th.randn(1,2,1,2,1, requires_grad=True)\n",
    "out = y.sigmoid()\n",
    "print(out,out.shape)\n",
    "out_clone = out.clone().squeeze()\n",
    "print(out_clone)\n",
    "detach_out = out.detach()\n",
    "print(detach_out, detach_out.shape)\n",
    "squezee_out = detach_out.squeeze()\n",
    "print(squezee_out, squezee_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 6, 3, 8])\n",
      "tensor([[1, 2],\n",
      "        [4, 3]])\n"
     ]
    }
   ],
   "source": [
    "# torch logistic selection by api\n",
    "x = th.tensor([1, 2, 3, 4])\n",
    "y = th.tensor([5, 6, 7, 8])\n",
    "condition = th.tensor([True, False, True, False])\n",
    "\n",
    "# torch.where()函数根据条件选择元素\n",
    "result = th.where(condition, x, y) #  true select the first array, false select the second array\n",
    "condition = x < 3\n",
    "compa_result = th.where(condition, x, y) #  result = [1,2,7,8]\n",
    "\n",
    "print(result) #  tensor([1, 6, 3, 8])\n",
    "\n",
    "# gather api for index mapping\n",
    "# 创建示例输入张量\n",
    "input = th.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# 创建索引张量\n",
    "index = th.tensor([[0, 1], [1, 0]])\n",
    "\n",
    "# 在维度 1 上进行索引收集\n",
    "output = th.gather(input, 1, index)  # 在一维数据进行钱两行数据的mapping \n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 37\u001b[0m\n\u001b[1;32m     25\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# data augmentation for images\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# transform = transforms.Compose([\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#     transforms.RandomCrop(size=224),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#     transforms.ToTensor(),\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# ])\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m myDataset \u001b[38;5;241m=\u001b[39m CustomDataset(data, labels, transform\u001b[38;5;241m=\u001b[39m\u001b[43mtransform\u001b[49m)\n\u001b[1;32m     38\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[1;32m     39\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(myDataset, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transform' is not defined"
     ]
    }
   ],
   "source": [
    "# Data set\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        super().__init__(data, labels)\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "\n",
    "# Reading from some directory to get the data and labels \n",
    "data = []\n",
    "labels = []\n",
    "# data augmentation for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(size=224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomErasing(),\n",
    "    transforms.GaussianBlur(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "myDataset = CustomDataset(data, labels, transform=transform)\n",
    "batch_size = 64\n",
    "loader = DataLoader(myDataset, 64, True)\n",
    "\n",
    "# get one batch data\n",
    "x, y = iter(loader)\n",
    "print(f'size of x,y: {(x.shape, y.shape)}') # data shape should be torch tensor (batch_size, (data_size)), (batch_size, (label_size))\n",
    "# normal training procedure\n",
    "num_epoches = 1000\n",
    "for i in range(num_epoches):\n",
    "    # for one epoach training (Used all data inside dataset for one time inside the iteration)\n",
    "    # each data and label are one batch data \n",
    "    for curr_data, true_label in loader:\n",
    "        # train\n",
    "        pass\n",
    "\n",
    "# split dataset to train and test set\n",
    "data_length = myDataset.__len__()\n",
    "train_ratio = 0.8\n",
    "train_length = int(train_ratio * data_length)\n",
    "test_length = data_length - train_length\n",
    "\n",
    "train_dataset, test_dataset = random_split(myDataset, [train_length , test_length])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CustomNet.__init__() missing 2 required positional arguments: 'input_shape' and 'feature_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(lstm_res)\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m---> 34\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mCustomNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# To achieve we training, we still need optimizer to perform gradient descent for updating nn weights\u001b[39;00m\n\u001b[1;32m     36\u001b[0m parser \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mArgumentParser(description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning hyperparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: CustomNet.__init__() missing 2 required positional arguments: 'input_shape' and 'feature_size'"
     ]
    }
   ],
   "source": [
    "# model architecture \n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import tqdm\n",
    "\n",
    "def cal_cnn_size(in_size, kernel_size, stride=1, padding=1):\n",
    "    # if result is not integer, use // operation to do a floor operation to get an int\n",
    "    return (in_size - kernel_size + 2 * padding) // stride + 1\n",
    "\n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, input_shape, feature_size) -> None:\n",
    "        super().__init__()\n",
    "        cnn_output_channel = 32\n",
    "        self.cnn_module = nn.Sequential(\n",
    "            nn.Conv2d(4, cnn_output_channel, kernel_size=7, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(5, stride=2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        cnn_output_size = cnn_output_channel * cal_cnn_size(input_shape[1], 7, 2, 1) * cal_cnn_size(input_shape[2], 7, 2, 1)\n",
    "        self.lstm = nn.LSTM(cnn_output_size, 1024, num_layers=3)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(1024, feature_size),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward pass\n",
    "        cnn_res = self.cnn_module(x)\n",
    "        lstm_res = self.lstm(cnn_res)\n",
    "        out = self.mlp(lstm_res)\n",
    "        return out\n",
    "    \n",
    "net = CustomNet()\n",
    "# To achieve we training, we still need optimizer to perform gradient descent for updating nn weights\n",
    "parser = argparse.ArgumentParser(description=\"learning hyperparameters\")\n",
    "parser.add_argument('--learning_rate', '-lr', type=float, default=0.001, help=\"learning rate\")\n",
    "args = parser.parse_args()\n",
    "optimizer = th.optim.Adam(net.parameters, lr=args.lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for i in range(num_epoches):\n",
    "    for idx, data in tqdm(enumerate(myDataset)):\n",
    "        input = data.unsqueeze(dim=2).float()\n",
    "        true_output = input.clone() #  单步预测\n",
    "        input, output = input.to(device), true_output.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model_out = net(input)\n",
    "        loss = criterion(model_out, output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# obtain the feature map from the pre-trained resenet model\n",
    "import torchvision.models as models\n",
    "\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet_wo_fc = nn.Sequential(*list(resnet.children())[:-1]) # remove the last fc layer\n",
    "# print(resnet)\n",
    "print(resnet_wo_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([1, 3, 6, 128, 256])\n",
      "cnn out shape: torch.Size([1, 8, 6, 64, 128])\n",
      "attn out shape: torch.Size([1, 4, 256]), weight shape: torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# cnn test\n",
    "cnn = nn.Conv3d(in_channels=3, out_channels=8, kernel_size=(3,3,3), stride=(1,2,2), padding=(1,1,1))\n",
    "x =  th.rand((1,3, 6, 128,256))\n",
    "print(f'x shape: {x.shape}')\n",
    "out = cnn(x)\n",
    "print(f'cnn out shape: {out.shape}')\n",
    "q = th.rand((1,4,256))\n",
    "k = th.rand((1,4,256))\n",
    "v = th.rand((1,4,256))\n",
    "attn = nn.MultiheadAttention(embed_dim=256, num_heads=4, batch_first=True)\n",
    "attn_out, weight = attn(q,k,v)\n",
    "print(f'attn out shape: {attn_out.shape}, weight shape: {weight.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi GPU parallel training\n",
    "## Distributed data parallel by utilizing multi processing\n",
    "1. num_process = num_gpus, every process is independent for model initialization, training but the model gradient and loss will be shared and synchornized after each batch iteration. And the model parameter update is independently updated\n",
    "2. Each process has its own portion of the full dataset which means there are several models trained by different dataset. And the parallel dataset is achieved by torch.utils.data.distributed.DistributedSampler function.\n",
    "3. `local_rank` is the variable to identify the process id. If `local_rank` = 0, this process is master and others are slaves.\n",
    "## Run the train file by distributed method\n",
    "```sh\n",
    "python -m torch.distributed.launch --nproc_per_node=2 --nnodes=1 train.py\n",
    "```\n",
    "`--nproc_per_node` means how many gpus for using in single pc\n",
    "`--nnodes` means how many pc used for training\n",
    "\n",
    "**Belows is a example to train a model net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data.distributed import DistributedSampler  # 负责分布式dataloader创建，也就是实现上面提到的partition。\n",
    "import argparse\n",
    "\n",
    "# 负责创建 args.local_rank 变量，并接受 torch.distributed.launch 注入的值\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--local_rank\", type=int, default=-1)\n",
    "args = parser.parse_args()\n",
    "\n",
    "# 每个进程根据自己的local_rank设置应该使用的GPU\n",
    "torch.cuda.set_device(args.local_rank)\n",
    "device = torch.device('cuda', args.local_rank)\n",
    "\n",
    "# 初始化分布式环境，主要用来帮助进程间通信\n",
    "torch.distributed.init_process_group(backend='nccl')\n",
    "\n",
    "# 固定随机种子\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# 初始化模型\n",
    "model = Net()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# 只 master 进程做 logging，否则输出会很乱\n",
    "if args.local_rank == 0:\n",
    "    tb_writer = SummaryWriter(comment='ddp-training')\n",
    "\n",
    "# 分布式数据集\n",
    "train_sampler = DistributedSampler(train_dataset)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)  # 注意这里的batch_size是每个GPU上的batch_size\n",
    "\n",
    "# 分布式模型\n",
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
